{
  "markdown": "[Skip to main content](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/#__docusaurus_skipToContent_fallback)\n\n[![Axis Communications Logo](https://developer.axis.com/img/axis-logo.svg)\\\\\n**Axis developer documentation**](https://developer.axis.com/)\n\n```\n\n```\n\n[Blog](https://developer.axis.com/blog/)\n\n- [Computer vision](https://developer.axis.com/computer-vision/)\n- [Computer vision on device](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/#)\n\n  - [Develop your own deep learning application](https://developer.axis.com/computer-vision/computer-vision-on-device/develop-your-own-deep-learning-application/)\n  - [Axis Deep Learning Processing Unit (DLPU)](https://developer.axis.com/computer-vision/computer-vision-on-device/axis-dlpu/)\n  - [Supported frameworks](https://developer.axis.com/computer-vision/computer-vision-on-device/supported-frameworks/)\n  - [Quantization](https://developer.axis.com/computer-vision/computer-vision-on-device/quantization/)\n  - [Deep Learning Processing Unit (DLPU) model conversion](https://developer.axis.com/computer-vision/computer-vision-on-device/dlpu-model-conversion/)\n  - [General suggestions](https://developer.axis.com/computer-vision/computer-vision-on-device/general-suggestions/)\n  - [Recommended model architecture](https://developer.axis.com/computer-vision/computer-vision-on-device/recommended-model-architecture/)\n  - [Optimization tips](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/)\n  - [Test your model](https://developer.axis.com/computer-vision/computer-vision-on-device/test-your-model/)\n  - [Glossary](https://developer.axis.com/computer-vision/computer-vision-on-device/glossary/)\n- [How-to guides](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/#)\n\n\n- [Home page](https://developer.axis.com/)\n- Computer vision on device\n- Optimization tips\n\nOn this page\n\n# Optimization tips\n\nThis document provides optimization tips for each Deep Learning Processing Unit (DLPU). It is meant for a more advanced audience, that want to obtain the best performance possible from their model investing more time in the optimization process. If you are not an expert, we recommend using only the models provided in the [recommended model architecture](https://developer.axis.com/computer-vision/computer-vision-on-device/recommended-model-architecture/) section of this documentation or in the [Axis Model Zoo](https://github.com/AxisCommunications/axis-model-zoo).\n\n## ARTPEC-7 [​](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/\\#artpec-7 \"Direct link to ARTPEC-7\")\n\nThe ARTPEC-7 DLPU has a dedicated memory for the DLPU. To maximize the DLPU's performance, it is recommended to use lightweight models that can fit in this memory, such as SSD MobileNet v2 300x300.\n\nWhen converting your model to EdgeTPU using `edgetpu-converter`, you may receive warnings about instructions that cannot be executed by the TPU. It is important to avoid using these instructions in your model. Both per-channel and per-tensor quantization offer similar performance, but per-channel quantization is recommended for better accuracy. For more details on how to optimize your model for ARTPEC-7 DLPU, refer to the [EdgeTPU documentation](https://coral.ai/docs/).\n\n## ARTPEC-8 [​](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/\\#artpec-8 \"Direct link to ARTPEC-8\")\n\nThe ARTPEC-8 DLPU performs well with models of any size, as long as they fit in the device's memory. This allows for better performance with larger models compared to ARTPEC-7. Here are some additional optimizations to enhance DLPU performance:\n\n- **Use per-tensor quantization.**\n- Prefer regular convolutions over depth-wise convolutions, which means that architecture like RegNet-18 are more efficient than MobileNet.\n- Optimal kernel size is 3x3.\n- Use stride 2 whenever possible as it is natively supported by the convolution engine. For other cases, consider using pooling.\n- Ensure the number of filters per convolution block is a multiple of 6.\n- Applying ReLU as the activation function after a convolution will result in a faster fused layer.\n- Sparsification can improve the performance of the model.\n\nHere is also a more detailed table of specific supported operators for the ARTPEC-8 DLPU:\n\n| **Operator Category** | **Operators** |\n| --- | --- |\n| Neural Network | FullyConnected, Conv2d, DepthwiseConv2d, TransposeConv, MaxPool2d, AveragePool2d |\n| Data Manipulation | Concatenation, Reshape, ExpandDims, Squeeze, Slice, StridedSlice, Gather, GatherNd, OneHot, Split, Transpose, ResizeNearestNeighbor, ResizeBilinear, Cast |\n| Math | Add, AddN, Mul, Div, FloorDiv, Pow, Square, Sin, Tanh, Abs, Neg, Sqrt, Floor, Minimum, Maximum |\n| Comparison | Equal, NotEqual, Less, LessEqual, Greater, GreaterEqual |\n| Logic | LogicalNot, LogicalAnd, LogicalOr |\n| Activation Functions | Relu, Relu6, Softmax, Gelu, Elu, HardSwish |\n| Reduction | ReduceMin, ReduceMax, ReduceAny, ReduceProd |\n| Indexing | ArgMin, ArgMax |\n\n## ARTPEC-9 [​](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/\\#artpec-9 \"Direct link to ARTPEC-9\")\n\nThe ARTPEC-9 DLPU performs well with models of any size, as long as they fit in the device's memory.\nHere are some optimization tips to further increase performance.\n\n- Tensors with up to 4 dimensions are supported.\n- A `Batch` dimension >1 is not supported.\n- `NHWC` tensors are supported.\n- Most operations are not supported when the input or output tensor depths are too large.\n- Use `ReLU6` as activation function when possible.\n- Avoid explicit padding when possible.\n- It is most optimal to use filters evenly divisible by 16.\n\nBelow is a detailed table of operators supported on the ARTPEC-9 DLPU, along with operator specific\nrestrictions. Unsupported operations or supported operations that do not meet the requirements will\nbe automatically offloaded to the CPU.\n\n| **Operator** | **Restrictions** |\n| --- | --- |\n| Add | Element by element addition is supported. |\n| AveragePool | \\- Pooling size 3 x 3, with stride 1, 1 and `SAME` padding is supported.<br> \\- \"Mean\" average pooling is supported where the pooling size is 7 or 8 and the input width and height is equal to the pool size. |\n| Concat | \\- Output quantization scale smaller than the input quantization scale divided by 128 is not supported. <br> \\- If concatenating along the channel dimension, the channel dimension of every input tensor must be a multiple of 16. |\n| Constant | No specific restrictions. |\n| Conv2D | \\- `HWIO` format weights are supported.<br> \\- The supported kernel heights and widths (the kernel does not have to be square) are: { 1, 2, 3, 5, 7, 9 }. <br> \\- The supported strides (the height and width stride have to match) are: { 1, 2 }.<br> \\- For kernels with height or width >7, only a stride of 1 is supported.<br> \\- `SAME` and `VALID` padding are supported.<br> \\- `I*W/O` must be between 0 and 65536, where:<br>     \\- `I` is the input quantization scale.<br>     \\- `W` is the weight quantization scale.<br>     \\- `O` is the output quantization scale. |\n| DepthToSpace | \\- A block size of 2 is supported.<br> \\- Depth must be a multiple of the square of the block size. |\n| DepthwiseConvolution2D | \\- `HWIM` format weights are supported.<br> \\- The supported kernel heights and widths (the kernel does not have to be square) are: { 1, 2, 3, 5, 7, 9 }.<br> \\- The supported strides (the height and width stride have to match) are: { 1, 2 }.<br> \\- For kernels with height or width >7, only a stride of 1 is supported.<br> \\- `SAME` and `VALID` padding are supported.<br> \\- A channel multiplier of 1 is supported. A channel multiplier >1 is not supported.<br> \\- `I*W/O` must be between 0 and 65536, where:<br>     \\- `I` is the input quantization scale.<br>     \\- `W` is the weight quantization scale.<br>     \\- `O` is the output quantization scale. |\n| FullyConnected | \\- `HWIO` format weights are supported, `H` and `W` must be 1.<br> \\- `I*W/O` must be between 0 and 65536, where:<br>     \\- `I` is the input quantization scale.<br>     \\- `W` is the weight quantization scale.<br>     \\- `O` is the output quantization scale. |\n| LeakyReLU | Alpha must be less than 1 and greater than 0. |\n| MaxPool | \\- Supported configurations:<br>     \\- 1 x 1 pooling size, 2, 2 stride (equivalent to downsample 2 x 2).<br>     \\- 2 x 2 pooling size, 2, 2 stride, `VALID` padding, input sizes must be even.<br>     \\- 2 x 2 pooling size, 2, 2 stride, `SAME` padding, input sizes must be odd.<br>     \\- 3 x 3 pooling size, 2, 2 stride, `VALID` padding, input sizes must even, maximum tensor width is 417.<br>     \\- 3 x 3 pooling size, 2, 2 stride, `SAME` padding, input sizes must be odd, maximum tensor width is 417.<br>     \\- 1, 1 stride with pooling sizes up to 9x9 for `VALID` padding.<br>     \\- 1, 1 stride with pooling sizes up to 17x17 for `SAME` padding.<br> \\- Input size must not be smaller than the pooling size. |\n| MeanXY | \\- Supports mean reduction of `H x W` dimensions to 1 x 1.<br> \\- Only supports:<br>     \\- `N x 7 x 7 x C` input with `N x 1 x 1 x C` output.<br>     \\- `N x 8 x 8 x C` input with `N x 1 x 1 x C` output. |\n| Mul | \\- The multiplication of a tensor with a constant tensor is supported when the constant shape is `1 x 1 x 1 x C`.<br> \\- The multiplication of a variable with a scalar constant is supported when the quantized values in the output are the same as the input. |\n| Pad | \\- Only zero padding in the `H` and `W` dimension is supported.<br> \\- Padding of up to 7 each side of the tensor in those dimensions is supported.<br> \\- Padding amounts can differ per side, e.g. pad of 1 before the tensor in the `H` dimension and a pad of 3 after the tensor in the `H` dimension.<br> \\- Quantization for input and output tensors must be identical. |\n| Reinterpret quantization | No specific restrictions. |\n| ReLU | Lower bound must be less than the upper bound. |\n| Requantize | \\- Output quantization scale smaller than the input quantization scale divided by 128 is not supported.<br> \\- Requantize with different input/output type is supported. |\n| Reshape | No specific restrictions. |\n| Resize | \\- The resized height or width must be `2n` or `2n-1` where `n` is the original height or width.<br> \\- If resized height and width are not both odd or both even the result might be less accurate.<br> \\- Some Resize Bilinear configurations ( `align_corners=True`, `half_pixel_centres=True` when heights and widths are not both even or both odd) produce inaccurate results. |\n| Sigmoid | The output for sigmoid always has a quantization zero point equal to the minimum value of the quantized data type and a quantization scale of 1 / 256. |\n| Split | If splitting along the channel dimension, the channel dimension of every output tensor must be a multiple of 16. |\n| Tanh | The output for tanh always has a quantization zero point equal to the middle value of the quantized data type and a quantization scale of 1 / 128. |\n| TransposeConvolution2D | \\- `HWIO` format weights are supported.<br> \\- The supported kernel heights and widths (the kernel does not have to be square) are: { 1, 2, 3, 5, 7, 9 }.<br> \\- Only a stride of 2 is supported.<br> \\- `SAME` and `VALID` padding are supported.<br> \\- `I*W/O` must be between 0 and 65536, where:<br>     \\- `I` is the input quantization scale.<br>     \\- `W` is the weight quantization scale.<br>     \\- `O` is the output quantization scale. |\n\n## CV25 [​](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/\\#cv25 \"Direct link to CV25\")\n\nFor CV25, model quantization and optimizations are mainly performed by the compiler. It is recommended to refer to the documentation provided with the Ambarella SDK for more information.\n\nOne important consideration is to have a model with an input size that is a multiple of 32. Otherwise, padding will be required for the input, making the conversion process slightly more complex, and the model less efficient.\n\nLast updated on **Aug 27, 2025**\n\n[Previous\\\\\n\\\\\nRecommended model architecture](https://developer.axis.com/computer-vision/computer-vision-on-device/recommended-model-architecture/) [Next\\\\\n\\\\\nTest your model](https://developer.axis.com/computer-vision/computer-vision-on-device/test-your-model/)\n\n- [ARTPEC-7](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/#artpec-7)\n- [ARTPEC-8](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/#artpec-8)\n- [ARTPEC-9](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/#artpec-9)\n- [CV25](https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/#cv25)\n\nCOMMUNITY\n\n- [Axis Developer Community](https://axis.com/developer-community)\n- [Axis on GitHub](https://github.com/AxisCommunications)\n\nSOCIAL\n\n- [LinkedIn](https://www.linkedin.com/company/axis-communications)\n- [YouTube](https://www.youtube.com/@AxisCommunications)\n\nLEGAL AND COMPLIANCE\n\n- [Legal](https://www.axis.com/legal)\n- [Privacy](https://www.axis.com/privacy)\n\n© 2025 Axis Communications AB. All rights reserved.",
  "metadata": {
    "og:image": "https://developer.axis.com/img/social.jpeg",
    "docusaurus_tag": "docs-default-current",
    "language": "en",
    "ogUrl": "https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/",
    "og:url": "https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/",
    "ogImage": "https://developer.axis.com/img/social.jpeg",
    "title": "Optimization tips | Axis developer documentation",
    "og:locale": "en",
    "docsearch:language": "en",
    "docusaurus_version": "current",
    "description": "This document provides optimization tips for each Deep Learning Processing Unit (DLPU). It is meant for a more advanced audience, that want to obtain the best performance possible from their model investing more time in the optimization process. If you are not an expert, we recommend using only the models provided in the recommended model architecture section of this documentation or in the Axis Model Zoo.",
    "og:description": "This document provides optimization tips for each Deep Learning Processing Unit (DLPU). It is meant for a more advanced audience, that want to obtain the best performance possible from their model investing more time in the optimization process. If you are not an expert, we recommend using only the models provided in the recommended model architecture section of this documentation or in the Axis Model Zoo.",
    "twitter:image": "https://developer.axis.com/img/social.jpeg",
    "twitter:card": "summary_large_image",
    "og:title": "Optimization tips | Axis developer documentation",
    "generator": "Docusaurus v3.9.1",
    "favicon": "https://developer.axis.com/img/favicon.ico",
    "docsearch:version": "current",
    "ogDescription": "This document provides optimization tips for each Deep Learning Processing Unit (DLPU). It is meant for a more advanced audience, that want to obtain the best performance possible from their model investing more time in the optimization process. If you are not an expert, we recommend using only the models provided in the recommended model architecture section of this documentation or in the Axis Model Zoo.",
    "ogLocale": "en",
    "docusaurus_locale": "en",
    "docsearch:docusaurus_tag": "docs-default-current",
    "ogTitle": "Optimization tips | Axis developer documentation",
    "viewport": "width=device-width, initial-scale=1.0",
    "scrapeId": "65f2bc20-4885-420d-a805-20f970be2361",
    "sourceURL": "https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/",
    "url": "https://developer.axis.com/computer-vision/computer-vision-on-device/optimization-tips/",
    "statusCode": 200,
    "contentType": "text/html",
    "proxyUsed": "basic",
    "cacheState": "miss",
    "indexId": "2001874f-5b16-4ce7-971c-803551c21072",
    "creditsUsed": 1
  }
}